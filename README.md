# MMRQA (Multi-Modal Retrieval Question Answering)

A proof-of-concept implementation for multi-modal document processing and semantic retrieval.

## ğŸ› ï¸ Implementation Status
- [x] Core text processing pipeline
- [x] Image feature extraction
- [x] Speech-to-text conversion
- [ ] Vector database integration
- [ ] Hybrid search implementation
- [ ] API endpoints

## ğŸ“¦ Installation

### System Requirements
- Python 3.9+
- FFmpeg (for audio processing)
```bash
# MacOS
brew install ffmpeg swig
```

## ğŸ§  Core Modules

### System Architecture
```plaintext
[User Interface]
   â”‚
   â–¼ HTTP Upload/Query
[FastAPI Backend]
   â”‚
   â”œâ”€â–¶ Text Files â†’ PyMuPDF Parsing â†’ BERT Encoding â†’ Vector Database
   â”œâ”€â–¶ Image Files â†’ CLIP Encoding     â†’ Vector Database
   â””â”€â–¶ Voice Files â†’ Whisper to Text â†’ BERT Encoding â†’ Vector Database
   â”‚
   â–¼ Query Request
[Hybrid Retrieval System] (Keyword + Vector Search)
   â”‚
   â–¼ Retrieved Context
[Generation System] (LangChain Orchestration + GPT-4)
   â”‚
   â–¼ Generated Answer
[User Interface]
```
### File Processors
```bash
processors/
â”œâ”€â”€ text_processor.py    # PDF/Word parsing with BERT encoding
â”œâ”€â”€ image_processor.py   # CLIP-based image feature extraction
â””â”€â”€ audio_processor.py   # Whisper speech-to-text + BERT encoding
```

## ğŸ” Test
```bash
python main.py
```
